\chapter{Comparing Algorithms}


% it 1
With the {\tt norMmix} package explained, we can turn to comparing it to 
existing methods. As previously stated, the implementation representing the 
EM-algorithm is the {\tt mclust} package. It will be used with very little 
deviation from out-of-the-box, safe for restriction of the covariance models.
This is done, so we can compare like with like.
The specific command that performs the EM-algorithm is:

\begin{Schunk}
\begin{Sinput}
>     mclust::Mclust(x, G=cl, modelNames=mo)$BIC
\end{Sinput}
\end{Schunk}

Where {\tt cl} is a vector of integers of however many components we are trying 
to fit and {\tt mo} are the model names:

\begin{Schunk}
\begin{Soutput}
 [1] "EII" "VII" "EEI" "VEI" "EVI" "VVI" "EEE" "VEE" "EVV" "VVV"
\end{Soutput}
\end{Schunk}

The {\tt \$BIC} element of the results is taken as the main tool for model 
selection, as it is advertised in the package authors paper \cite{Scr16}.

There is however a small but crucial change applied to these results.
The {\tt mclust} package authors have flipped the definition of the BIC to mean:
\begin{equation} 
    2 ln(\hat{L}) - ln(n) \#\{par\}
\end{equation}
instead of the more common
\begin{equation} 
    ln(n) \#\{par\} - 2 ln(\hat{L})
\end{equation}
Where $n$ is the number of observations, \#\{par\} is the cardinality of the 
parameter vector and $\hat{L}$ is the estimated log-likelihood.

So, even if not explicitly mentioned, we use the negative of the values returned
by {\tt mclust}.

Another thing that should be stated before all else is the difference in 
initialization between {mclust}'s pre-clustering and CLARA. CLARA is dependent
on random number generators (RNG). As such, unless a fixed seed is chosen, 
every iteration of CLARA will return a different result. Unlike {\tt mclust}, 
which will, for given data, always return the same results. The effect on the 
following findings is that results will spread out for data obtained from 
CLARA results.


% it 1
First, we illustrate the structure of the graphical results we will be 
presenting hereafter. The basic shape of the plots will be the BIC value 
plotted against the number of components. This is in line with {\tt mclust}'s
manner of visualizing data, however since our method is to some extent RNG 
dependent, we are forced to display multiple runs of the algorithm on the same
graph. Therefore we split the plot according to covariance model, putting 10
models in 10 graphs in a plot. Here an example:


\begin{figure}[h!]
    \begin{Rgraph}[0.9]
\includegraphics{chapter3-bicplotdemoplot}
    \caption{Example of Comparison Plot}
    \label{fig:ExPlot}
    \end{Rgraph}
\end{figure}

As can be seen from the formula of the BIC value, lower is better. When 
selecting a model based on BIC, we take the model and component with the 
lowest value to be the best fitting model. Although this may not necessarily
the 'correct' model, that is, the model from which the data arises.

There are many ways in which this type of model selection might miss the 
correct model, for example by 'gluing together' multiple components into one,
or covering the dataset in a 'patchwork' of smaller components, to name a few.

We will discuss them as they arise in the following analysis of simulations

The simulations were set up very simply. An \Rp script was written and in each
the {\tt norMmix} package is loaded, the datasets are defined and {\tt fitnMm}
was applied a number of times. An example script can be found in the appendix
\ref{App:sims}.

A few things of interest are what happens:
\begin{itemize}
    \item To time needed for the simulation
    \item When we vary the sample size of the data sets.
    \item When the generating mixture is 'difficult'.
    \item When the data does not arise from a normal mixture.
\end{itemize}

The data used here should have been provided along with this thesis in digital 
form in a folder called {\tt /simulations}


\section{Time Analysis}


The data used here is taken from the subfolder {\tt /simulations/2time}.
From these, the system time was extracted and analyzed as can be gleaned from
the following code. In it, we apply \Rp's {\tt lm} function for fitting linear 
models to the times returned by the function call:
\begin{Schunk}
\begin{Sinput}
>     system.time(norMmixMLE(x, ...))[[1]]
\end{Sinput}
\end{Schunk}
We make here a choice that does not preserve any generality, as 
{\tt system.time} produces more results, that could hold important information.
However, since there is quite some measurement error to be expected as time 
approaches zero, we will content ourselves with lower expectations to the 
accuracy of the following results.


\begin{Schunk}
\begin{Sinput}
>     library(norMmix, lib.loc="~/ethz/BA/norMmix.Rcheck/")
>     # change this dir to whereever the simulations are saved
>     mainsav <- normalizePath("~/ethz/BA/Rscripts/")
>     savdir <- file.path(mainsav, "2time")
>     filelist <- list.files(savdir, pattern=".rds")
>     filelist <- grep("mcl.rds", filelist, invert=TRUE, value=TRUE)
>     f <- lapply(file.path(savdir,filelist), function(j) readRDS(j)$fit)
>     times <- unlist(lapply(f, function(j) extracttimes(j)[,,1]))
>     dims <- unlist(lapply(f, function(j) attr(extracttimes(j), "p")))
>     size <- unlist(lapply(f, function(j) attr(extracttimes(j), "n")))
>     ddims <- rep(dims, each=80)
>     ssize <- rep(size, each=80)
>     pars <- unlist(lapply(f, npar))
>     r <- lm(times ~ pars + ddims + ssize)
>     summary(r)
\end{Sinput}
\begin{Soutput}
Call:
lm(formula = times ~ pars + ddims + ssize)

Residuals:
   Min     1Q Median     3Q    Max 
-86.89  -7.45  -1.55   6.30 556.32 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -1.727e+01  8.274e-01  -20.87   <2e-16 ***
pars         9.729e-01  1.056e-02   92.16   <2e-16 ***
ddims       -3.749e+00  2.216e-01  -16.92   <2e-16 ***
ssize        9.258e-03  3.887e-04   23.82   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 21.57 on 7916 degrees of freedom
Multiple R-squared:  0.559,	Adjusted R-squared:  0.5588 
F-statistic:  3344 on 3 and 7916 DF,  p-value: < 2.2e-16
\end{Soutput}
\end{Schunk}

The necessary time appears to be well explained by the parameter count.
The purpose of this thesis is not to conduct complexity analysis, so we will
leave it at this, satisfying our curiosity with a cursory look in figure 
\ref{fig:time}, where we plot system time against parameter length.

\begin{figure}[h!]
    \begin{Rgraph}[0.9]
\begin{Schunk}
\begin{Sinput}
>     plot(times~pars, log="xy", yaxt="n", xaxt="n", type="n")
>     legend("bottomright", legend=c("MW214", "MW34","MW51"),
+            fill=nMmcols[c(3,4,2)])
>     points(times[1:(80*30)]~pars[1:(80*30)], 
+            log="xy", yaxt="n", xaxt="n", col=nMmcols[3])
>     points(times[(80*30+1):(80*60)]~pars[(80*30+1):(80*60)]
+            , log="xy", yaxt="n", xaxt="n", col=nMmcols[4])
>     points(times[(60*80+1):(80*90)]~pars[(60*80+1):(80*90)], 
+            log="xy", yaxt="n", xaxt="n", col=nMmcols[2])
>     grid()
>     sfsmisc::eaxis(1)
>     sfsmisc::eaxis(2)
\end{Sinput}
\end{Schunk}
\includegraphics{chapter3-figtime}
    \caption{Log-log Plot of System Time against Parameter Length}
    \label{fig:time}
    \end{Rgraph}
\end{figure}

We can see that time is almost one to one proportional to parameter length.
It should be noted, that {\tt MW51} is a very simple mixture. It is therefore 
sensible, that MLE should find an optimum faster.

\clearpage

\section{Behaviour in {\tt n}}
\label{sec:ben}

% it 1
What we would expect and like to see as we increase sample size, is a decrease
in scattering of BIC values. To that end we again use simulation data 
{\tt /2time}. In particular we show here the results of fitting to mixture 
model {\tt MW34}, shown in figure \ref{fig:MW34}. The graphs 
\ref{fig:bicmw34first} and \ref{fig:bicmw34second} show three columns
of BIC plots, each representing different sample sizes, with 
$n = \{500, 1000, 2000\}$ respectively. Furthermore, the BIC values were 
divided by the samplesize, to normalize the values to an equal scale.

\begin{figure}[h]
    \begin{Rgraph}[0.9]
\includegraphics{chapter3-figMW34}
    \caption{The mixture model {\tt MW34}, a three dimensional, two component
             mixture with one smaller, lesser weighted component inside a 
             smaller one.}
    \label{fig:MW34}
    \end{Rgraph}
\end{figure}


\begin{figure}[h!]
    \begin{Rgraph}[0.9]
\includegraphics{chapter3-figmw34bicfirst}
    \caption{BIC values of {\tt MW34} with $n=2000$}
    \label{fig:bicmw34first}
    \end{Rgraph}
\end{figure}

As can be seen the desired effect is achieved. Of note are the behaviour of 
the model {\tt VEI}, where the increase in observation corrects a selection
error appearing at $n=500$. Furthermore, the correct model {\tt VVI} exhibits
a very tight grouping. The instances where {\tt mclust} is better than 
{\tt norMmix} are quite infrequent.

This type of analysis was also conducted with mixture objects {\tt MW214} and 
{\tt MW51}, but were ommited due to the lack of clear results. They are 
provided in the appendix \ref{app:ben}, with brief discussions.

\begin{figure}[h!]
    \begin{Rgraph}[0.9]
\includegraphics{chapter3-figmw34bicsecond}
    \caption{BIC values of {\tt MW34} with $n=2000$}
    \label{fig:bicmw34second}
    \end{Rgraph}
\end{figure}

\clearpage

\section{Difficult Mixtures}
\label{sec:dif}

% it 1
In this section we analyze the two mixtures given by {\tt MW215} and {\tt MW214}.
These are a trimodal and a claw-like distribution. These types of mixtures were 
also discussed in \cite{Mar92}, in the univariate case, where they proved to be 
difficult to fit.

First the trimodal mixture shown in figure \ref{fig:MW215}. The difficulty 
lies in the components of various sizes lying close together.

\begin{figure}
\begin{Rgraph}[0.9]
\includegraphics{chapter3-figMW215}
    \caption{Trimodal mixture {\tt MW215}. Three equally weighted, oriented, and
             shaped components of different volumes along the diagonal}
    \label{fig:MW215}
\end{Rgraph}
\end{figure}


\begin{figure}[h!]
    \begin{Rgraph}[0.9]
\begin{Schunk}
\begin{Sinput}
>     compplot(clarabic, mclbic, mclustbic, main="Fit of MW34")
\end{Sinput}
\end{Schunk}
\includegraphics{chapter3-figMW34bic}
    \caption{BIC values of {\tt MW34}, correct: {\tt model="VVI", k=2}}
    \label{fig:bicMW34}
    \end{Rgraph}
\end{figure}

We can see, that in many cases both initialization methods {\tt clara} and
{\tt mclVVV} manage to achieve a lower BIC value than {\tt mclust}. Although in
the case of the correct model and cluster, {\tt k=3, model="VEE"} the three 
algorithms coincide.

A search for best values reveals, that the best models selected are in almost 
all cases the correct model.

\begin{Schunk}
\begin{Soutput}
     model   count
[1,] "2 VVI" "49" 
[2,] "4 VEI" "1"  
\end{Soutput}
\end{Schunk}

The one incorrect model looks like this:

\begin{figure}[h]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
\includegraphics{chapter3-figerrorMW215}
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
        \centering
\includegraphics{chapter3-figerrorMW215x}
    \end{minipage}
\end{figure}

and has the weights: 0.942, 0.0321, 0.0244, 0.002, again, an issue of 
spurious clusters.

Now for the claw-like mixture, {\tt MW214}. It is a mixture of six components
and a very simple {\tt "VII"} covariance model. A large encompassing component
and five smaller, lightly wheighted components closely together along the 
diagonal. The inherent difficulty lies in the fact that the components overlap
and are close together as well. It is shown in figure \ref{fig:MW214}.

\begin{figure}[h!]
    \begin{Rgraph}[0.9]
\includegraphics{chapter3-figMW214}
    \caption{Claw-like mixture}
    \label{fig:MW214}
    \end{Rgraph}
\end{figure}



\begin{figure}[h!]
    \begin{Rgraph}[0.9]
\includegraphics{chapter3-figMW214bic}
    \caption{BIC values of claw-like mixture. Best fit: {\tt model="VEE", k=8},
             correct: {model="VII", k=6}}
    \label{}
    \end{Rgraph}
\end{figure}

here some examples of fitted mixtures

\begin{figure}[h!]
    \begin{Rgraph}[0.9]
\includegraphics{chapter3-fig214fit}
    \caption{Best Fit over $n=$ model selections. {\tt model="VEE", k=8} Correct
             model {\tt model="VII", k=6}. Of Note Here are the Spurious 
             Clusters Appearing.}%whats n?? should be verbose
    \label{fig:MW214bestfit}
    \end{Rgraph}
\end{figure}

We can see, that, subtracting the obvious hiccups of the small erroneous
components, {\tt norMmix} has correctly found the 'intended' 
distribution. This is remarkable, given the small sample size and difficulty of distribution

\clearpage

\section{Nonnormal Mixtures}

here 2smi and 2var, maybe others as well.
here mention that coverage of algo is extremely patchy.
here 2smi:


\begin{figure}[h!]
    \begin{Rgraph}[0.9]
\includegraphics{chapter3-2smiplot}
    \end{Rgraph}
\end{figure}

While not very spectacular, the graphs show that even at large parameter
counts our algorithm closes in on the same values as {\tt mclust}.
At these dimensions it is difficult to compare if these are actually 
equal, or even similar fits, but going by BIC values, it is at the very 
least equally viable as a working model.

To illustrate, here are the parameter sizes for this simulation:
\begin{Schunk}
\begin{Soutput}
  EII VII EEI VEI EVI VVI EEE VEE  EVV  VVV
1  21  21  40  40  40  40 230 230  230  230
2  42  43  61  62  80  81 251 252  460  461
3  63  65  82  84 120 122 272 274  690  692
4  84  87 103 106 160 163 293 296  920  923
5 105 109 124 128 200 204 314 318 1150 1154
6 126 131 145 150 240 245 335 340 1380 1385
7 147 153 166 172 280 286 356 362 1610 1616
8 168 175 187 194 320 327 377 384 1840 1847
\end{Soutput}
\end{Schunk}



\begin{figure}[h!]
    \begin{Rgraph}[0.9]
\includegraphics{chapter3-figtriris}
    \caption{Truncated Iris}
    \label{fig:triris}
    \end{Rgraph}
\end{figure}

\begin{figure}[h!]
    \begin{Rgraph}[0.9]
\includegraphics{chapter3-figloss}
    \caption{Loss data}
    \label{fig:loss}
    \end{Rgraph}
\end{figure}
