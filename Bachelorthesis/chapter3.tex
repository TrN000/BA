\chapter{Comparing Algorithms}


% it 1
With the {\tt norMmix} package explained, we can turn to comparing it to 
existing methods. As previously stated, the implementation representing the 
EM-algorithm is the {\tt mclust} package. It will be used with very little 
deviation from out-of-the-box, safe for restriction of the covariance models.
This is done, so we can compare like with like.
The specific command that performs the EM-algorithm is:

\begin{Schunk}
\begin{Sinput}
>     #mclust::Mclust(x, G=cl, modelNames=mo)$BIC
\end{Sinput}
\end{Schunk}

Where {\tt cl} is a vector of integers of however many components we are trying 
to fit and {\tt mo} are the model names:

\begin{Schunk}
\begin{Soutput}
 [1] "EII" "VII" "EEI" "VEI" "EVI" "VVI" "EEE" "VEE" "EVV" "VVV"
\end{Soutput}
\end{Schunk}

The {\tt \$BIC} element of the results is taken as the main tool for model 
selection, as it is advertised in the package authors paper \cite{Scr16}.

There is however a small but crucial change applied to these results.
The {\tt mclust} package authors have flipped the definition of the BIC to mean:
\begin{equation} 
    2 ln(\hat{L}) - ln(n) \theta
\end{equation}
instead of the more common
\begin{equation} 
    ln(n) \theta - 2 ln(\hat{L})
\end{equation}
Where $n$ is the number of observations, $\theta$ is the cardinality of the 
parameter vector and $\hat{L}$ is the estimated log-likelihood.

So even if not explicitly mentioned, we use the negative of the values returned
by {\tt mclust}.

Another thing that should be stated before all else is the difference in 
initialization between {mclust}'s pre-clustering and CLARA. CLARA is dependent
on random number generators (RNG). As such, unless a fixed seed is chosen, 
every iteration of CLARA will return a different result. Unlike {\tt mclust}, 
which will, for given data, always return the same results. The effect on the 
following findings is that results will spread out for data obtained from 
CLARA results.


% it 1
First, we illustrate the structure of the graphical results we will be 
presenting hereafter. The basic shape of the plots will be the BIC value 
plotted against the number of components. This is in line with {\tt mclust}'s
manner of visualizing data, however since our method is to some extent RNG 
dependent, we are forced to display multiple runs of the algorithm on the same
graph. Therefore we split the plot according to covariance model, putting 10
models in 10 graphs in a plot. Here an example:


\begin{figure}[h!]
    \centering
\includegraphics{chapter3-bicplotdemoplot}
    \caption{Example of Comparison Plot}
    \label{fig:ExPlot}
\end{figure}

As can be seen from the formula of the BIC value, lower is better. When 
selecting a model based on BIC, we take the model and component with the 
lowest value to be the best fitting model. Although this may not necessarily
the 'correct' model, that is, the model from which the data arises.

There are many ways in which this type of model selection might miss the 
correct model, for example by 'gluing together' multiple components into one,
or covering the dataset in a 'patchwork' of smaller components, to name a few.

We will discuss them as they arise in the following analysis of simulations

The simulations were set up very simply. An \Rp script was written and in each
the {\tt norMmix} package is loaded, the datasets are defined and {\tt fitnMm}
was applied a number of times. An example script can be found in the appendix
\ref{App:sims}.

here explain the various sections: time, n, p, difficult , nonnormal 
A few things of interest are what happens:
\begin{itemize}
    \item To time needed for the simulation
    \item When we vary the sample size of the data sets.
    \item When we vary the dimension of the data.
    \item When the generating mixture is 'difficult'.
    \item When the data does not arise from a normal mixture.
\end{itemize}

The data used here should have been provided along with this thesis in digital 
form in a folder called {\tt /simulations}


\section{Time Analysis}


The data used here is taken from the subfolder {\tt /simulations/2time}.
From these, the system time was extracted and analyzed as can be gleaned from
the following code.

\begin{Schunk}
\begin{Sinput}
>     library(norMmix, lib.loc="~/ethz/BA/norMmix.Rcheck/")
>     # change this dir to whereever the simulations are saved
>     mainsav <- normalizePath("~/ethz/BA/Rscripts/")
>     savdir <- file.path(mainsav, "2time")
>     filelist <- list.files(savdir, pattern=".rds")
>     filelist <- grep("mcl.rds", filelist, invert=TRUE, value=TRUE)
>     f <- lapply(file.path(savdir,filelist), function(j) readRDS(j)$fit)
>     times <- unlist(lapply(f, function(j) extracttimes(j)[,,1]))
>     dims <- unlist(lapply(f, function(j) attr(extracttimes(j), "p")))
>     size <- unlist(lapply(f, function(j) attr(extracttimes(j), "n")))
>     ddims <- rep(dims, each=80)
>     ssize <- rep(size, each=80)
>     pars <- unlist(lapply(f, npar))
>     r <- lm(times ~ pars + ddims + ssize)
>     summary(r)
\end{Sinput}
\begin{Soutput}
Call:
lm(formula = times ~ pars + ddims + ssize)

Residuals:
   Min     1Q Median     3Q    Max 
-86.89  -7.45  -1.55   6.30 556.32 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -1.727e+01  8.274e-01  -20.87   <2e-16 ***
pars         9.729e-01  1.056e-02   92.16   <2e-16 ***
ddims       -3.749e+00  2.216e-01  -16.92   <2e-16 ***
ssize        9.258e-03  3.887e-04   23.82   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 21.57 on 7916 degrees of freedom
Multiple R-squared:  0.559,	Adjusted R-squared:  0.5588 
F-statistic:  3344 on 3 and 7916 DF,  p-value: < 2.2e-16
\end{Soutput}
\end{Schunk}

The necessary time appears to be well explained by the parameter count.

\begin{figure}[h!]
    \centering
\begin{Schunk}
\begin{Sinput}
>     plot(times~pars, log="xy", yaxt="n", xaxt="n", type="n")
>     legend("bottomright", legend=c("MW214", "MW34","MW51"),
+            fill=nMmcols[c(3,4,2)])
>     points(times[1:(80*30)]~pars[1:(80*30)], 
+            log="xy", yaxt="n", xaxt="n", col=nMmcols[3])
>     points(times[(80*30+1):(80*60)]~pars[(80*30+1):(80*60)]
+            , log="xy", yaxt="n", xaxt="n", col=nMmcols[4])
>     points(times[(60*80+1):(80*90)]~pars[(60*80+1):(80*90)], 
+            log="xy", yaxt="n", xaxt="n", col=nMmcols[2])
>     grid()
>     sfsmisc::eaxis(1)
>     sfsmisc::eaxis(2)
\end{Sinput}
\end{Schunk}
\includegraphics{chapter3-figtime}
    \caption{Log-log Plot of System Time against Parameter Length}
    \label{fig:time}
\end{figure}

We can see that time is almost one to one proportional to parameter length.
It should be noted, that {\tt MW51} is a one component, standard normal 
distribution. It is therefore sensible, that MLE should find an optimum faster,
as it is a very simple mixture.


\section{Behaviour in {\tt n}}

% it 1
here show as expected narrower scattering as n increases


\begin{figure}[h!]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
\includegraphics{chapter3-fig5fit}
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
        \centering
\includegraphics{chapter3-fig10fit}
    \end{minipage}
\end{figure}

\begin{figure}[h!]
    \centering
\includegraphics{chapter3-fig20fit}
\end{figure}

further plots in \ref{App:time}


\section{Behaviour in {\tt p}}

% it 1
here show how norMmix is consistently competitive with mclust
The same data as in the last section was used to analyze the behaviour for 
varying dimensions, since they have a nice variation in dimensionality.
We plot the BIC values and see how they differ among dimensions.

\begin{figure}[h!]
\begin{Schunk}
\begin{Sinput}
>     plot(MW34)
\end{Sinput}
\end{Schunk}
\includegraphics{chapter3-figMW34}
\end{figure}



\begin{figure}[h!]
\begin{Schunk}
\begin{Sinput}
>     compplot(clarabic, mclbic, mclustbic, main="Fit of MW34")
\end{Sinput}
\end{Schunk}
\includegraphics{chapter3-figMW34bic}
\end{figure}

\section{Difficult Mixtures}

% it 1
here show behaviour in difficult cases
In this section we analyze the two mixtures given by {\tt MW215} and {\tt MW214}.
These are a trimodal and a claw-like distribution. These types of mixtures were 
also discussed in \cite{Mar92}, in the univariate case, where they proved to be 
difficult to fit.

First the trimodal mixture shown in figure \ref{fig:trimod}. The difficulty 
lies in the components of various sizes close together.


\begin{figure}[h!]
    \centering
\includegraphics{chapter3-figtrimod}
    \caption{BIC Values for the Trimodal mixture}
    \label{fig:trimod}
\end{figure}

We can see, that in many cases both initialization methods {\tt clara} and
{\tt mclVVV} manage to achieve a lower BIC value than {\tt mclust}. Although in
the case of the correct model and cluster, {\tt k=3, model="VEE"} the three 
algorithms coincide.

Now for the claw-like mixture, {\tt MW214}. It is a mixture of six components
and a very simple {\tt "VII"} covariance model. A large encompassing component
and five smaller, lightly wheighted components closely together along the 
diagonal. The inherent difficulty lies in the fact that the components overlap
and are close together as well. It is shown in figure \ref{fig:MW214}.

\begin{figure}[h!]
    \centering
\includegraphics{chapter3-figMW214}
    \caption{Claw-like mixture}
    \label{fig:MW214}
\end{figure}


\begin{Schunk}
\begin{Sinput}
>     savdir <- file.path(mainsav, "2init")
>     filenames <- list.files(savdir, pattern=".rds")
>     MW214fn <- grep("MW214", filenames, value="TRUE")
>     mclustfiles <- grep("mcl.rds", MW214fn, value=TRUE)
>     MW214fn <- grep("mcl.rds", MW214fn, value="TRUE", invert=TRUE)
>     claraMW <- grep("clara", MW214fn, value=TRUE)
>     mclMW <- grep("mclVVV", MW214fn, value=TRUE)
>     clarabic <- massbic(claraMW, savdir)
>     mclbic <- massbic(mclMW, savdir)
>     mclustbic <- readRDS(file.path(savdir,mclustfiles[1]))
\end{Sinput}
\end{Schunk}

\begin{figure}[h!]
\begin{Schunk}
\begin{Sinput}
>     compplot(clarabic, mclbic, mclustbic, main="Fit of MW214")
\end{Sinput}
\end{Schunk}
\includegraphics{chapter3-figMW214bic}
\end{figure}

here some examples of fitted mixtures

\begin{figure}[h!]
    \centering
\begin{Schunk}
\begin{Sinput}
>     f <- readRDS(file.path(savdir, claraMW[28]))
>     ff <- f$fit$nMm[8,8][[1]]
>     plot(ff$norMmix)
\end{Sinput}
\end{Schunk}
\includegraphics{chapter3-fig214fit}
\end{figure}

We can see, that, subtracting the obvious hiccups of the small erroneous
components, {\tt norMmix} has correctly found the 'intended' 
distribution. This is remarkable, given the small sample size and difficulty of distribution

\section{Nonnormal Mixtures}

here 2smi and 2var, maybe others as well.
here mention that coverage of algo is extremely patchy.
here 2smi:

\begin{Schunk}
\begin{Sinput}
>     savdir <- file.path(mainsav, "2smi")
>     filenames <- list.files(savdir, pattern=".rds")
>     fnclara <- grep("clara_seed", filenames, value=TRUE)
>     fnmclVV <- grep("mclVVV_see", filenames, value=TRUE)
>     fnmclus <- grep("__mcl.rds",  filenames, value=TRUE)
\end{Sinput}
\end{Schunk}

\begin{figure}[h!]
    \centering
\includegraphics{chapter3-2smiplot}
\end{figure}

While not very spectacular, the graphs show that even at large parameter
counts our algorithm closes in on the same values as {\tt mclust}.
At these dimensions it is difficult to compare if these are actually 
equal, or even similar fits, but going by BIC values, it is at the very 
least equally viable as a working model.

To illustrate, here are the parameter sizes for this simulation:
\begin{Schunk}
\begin{Soutput}
  EII VII EEI VEI EVI VVI EEE VEE  EVV  VVV
1  21  21  40  40  40  40 230 230  230  230
2  42  43  61  62  80  81 251 252  460  461
3  63  65  82  84 120 122 272 274  690  692
4  84  87 103 106 160 163 293 296  920  923
5 105 109 124 128 200 204 314 318 1150 1154
6 126 131 145 150 240 245 335 340 1380 1385
7 147 153 166 172 280 286 356 362 1610 1616
8 168 175 187 194 320 327 377 384 1840 1847
\end{Soutput}
\end{Schunk}




\begin{figure}[h!]
    \centering
\includegraphics{chapter3-figiris}
    \caption{Iris Dataset}
    \label{fig:iris}
\end{figure}

\begin{figure}[h!]
    \centering
\includegraphics{chapter3-figtriris}
    \caption{Truncated Iris}
    \label{fig:triris}
\end{figure}

\begin{figure}[h!]
    \centering
\includegraphics{chapter3-figloss}
    \caption{Loss data}
    \label{fig:loss}
\end{figure}
